# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rI_U_cD9p_YGWvTtXrbQok_ypD0cMm1V
"""


import requests
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
import datetime as dt
import mplcursors as mpc

url = "https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=AAPL&outputsize=full&apikey=BUU1TEFPHRAKI5LE"

try:
    res = requests.get(url)
    data = {}
    if res.status_code == 200:
        data = res.json()
except requests.exceptions.RequestException as e:
    print(f"Error -> {e}")
df = pd.json_normalize(data)
df_csv = pd.DataFrame(data)

df_csv.to_csv("results.csv")
df.to_json("results.json")

df = pd.read_json("results.json")

open_cols = df.loc[:, df.columns.str.contains("open")]
close_cols = df.loc[:, df.columns.str.contains("close")]
low_cols = df.loc[:, df.columns.str.contains("low")]
high_cols = df.loc[:, df.columns.str.contains("high")]
volume_cols = df.loc[:, df.columns.str.contains("volume")]
time_series = df.loc[:, df.columns.str.contains("high")]


def get_values(df, col_name):
    df = df.T
    df = df.reset_index()
    df = df.iloc[:, 1]
    df = pd.DataFrame(df)
    df.columns = [str(col_name)]
    return df


def get_time_series(df, col_name):
    df = df.T
    df = df.reset_index()
    df = df.iloc[:, 0]
    df = pd.DataFrame(df)
    df.columns = [str(col_name)]
    return df


open_cols = get_values(open_cols, "Open")
close_cols = get_values(close_cols, "Close")
low_cols = get_values(low_cols, "Low")
high_cols = get_values(high_cols, "High")
volume_cols = get_values(volume_cols, "Volume")

time_series = get_time_series(time_series, "Time Series")
time_series["Time Series"] = pd.to_datetime(
    time_series["Time Series"].apply(lambda x: x.split(".")[1])
)

data_table = pd.concat(
    [time_series, open_cols, close_cols, low_cols, high_cols, volume_cols], axis=1
)

data_table = data_table.iloc[::-1]
data_table = data_table.loc[
    data_table["Time Series"] >= pd.to_datetime("20240101T0000")
]
data_table = data_table.reset_index(drop=True)
columns_to_convert = ["Open", "Close", "Low", "High", "Volume"]
data_table[columns_to_convert] = data_table[columns_to_convert].astype(float)


# 1- Downloaded values types
data_table.dtypes

# 2- Records count
data_table.shape[0]

# 3- Columns titles
data_table.columns.tolist()

# 4- Source data types
data_table.info()

# 5- Date range
(
    str(data_table["Time Series"].min()).split(" ")[0]
    + " - "
    + str(data_table["Time Series"].max()).split(" ")[0]
)

# 6- The lowest closing price
data_table["Close"].min()

# 7- Average of the highest price in the day
data_table["High"].mean()

# 8- Sum of the trades through the date range
data_table["Volume"].sum()

# 9- The maximum open date
max_index = data_table["Open"].argmax()
max_open_date = data_table.iloc[max_index, 0]
data_table.iloc[max_index, [0, 1]]

# 10- The minimum open date
min_index = data_table["Open"].argmin()
min_open_date = data_table.iloc[min_index, 0]
data_table.iloc[min_index, [0, 1]]

# 11- Most Volatile Day
max_day = data_table["High"].sub(data_table["Low"], axis=0).argmax()
data_table.iloc[max_day, [0, 3, 4]]

# 12- Total trading days and Average shares traded
str(data_table.shape[0]) + " Days - " + str(data_table["Volume"].mean())

min_open_date = min_open_date.strftime("%Y%m%dT%H%M")
max_open_date = max_open_date.strftime("%Y%m%dT%H%M")

news_url_max = f"https://www.alphavantage.co/query?function=NEWS_SENTIMENT&limit=1000&tickers=AAPL&sort=EARLIEST&time_from={max_open_date}&apikey=BUU1TEFPHRAKI5LE"
news_url_min = f"https://www.alphavantage.co/query?function=NEWS_SENTIMENT&limit=1000&tickers=AAPL&sort=EARLIEST&time_from={min_open_date}&apikey=BUU1TEFPHRAKI5LE"


def get_news_data(url):
    news_res = requests.get(url)
    news_data = {}
    news_data = news_res.json()
    return pd.DataFrame(news_data), pd.json_normalize(news_data)


def get_feed_data(news_df_csv):
    news_df_csv = pd.DataFrame(news_df_csv["feed"])
    news_df = news_df_csv.iloc[:].to_dict().get("feed")
    news_df = pd.DataFrame(news_df).T
    news_df = news_df.reset_index(drop=True)
    news_df = news_df.loc[:, ["title", "summary", "time_published"]]
    news_df["time_published"] = news_df["time_published"].apply(
        lambda t: pd.to_datetime(str(t).split("T")[0])
    )
    news_df = (
        news_df.sort_values("time_published")
        .drop_duplicates(subset="time_published", keep="first")
        .reset_index(drop=True)
    )
    return news_df


news_df_csv_max, news_df_json_max = get_news_data(news_url_max)
news_df_csv_min, news_df_json_min = get_news_data(news_url_min)

news_df_csv_max.to_csv("max_news_results.csv")
news_df_json_max.to_json("max_news_results.json")
news_df_csv_min.to_csv("min_news_results.csv")
news_df_json_min.to_json("min_news_results.json")

max_df = get_feed_data(news_df_csv_max)
max_df = max_df.head(1)
min_df = get_feed_data(news_df_csv_min)
min_df = min_df.head(1)


def show_plot(date, is_max):
    fig, ax = plt.subplots()
    ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y-%m-%d"))
    ax.xaxis.set_major_locator(mdates.DayLocator(interval=9))
    ax.plot(
        data_table["Time Series"],
        data_table["Open"],
    )
    ax.axvspan(
        *mdates.datestr2num(
            [
                str(pd.to_datetime(date) - dt.timedelta(days=3)),
                str(pd.to_datetime(date) + dt.timedelta(days=3)),
            ]
        ),
        color="#90EE90" if is_max else "#FFE4E1",
        alpha=0.5,
    )
    # Enable hover annotations
    cursor = mpc.cursor(ax, hover=True)

    @cursor.connect("add")
    def on_add(sel):
        date_str = mdates.num2date(sel.target[0]).strftime("%Y-%m-%d")
        open_price = data_table[data_table["Time Series"] == date_str]["Open"].values[0]
        sel.annotation.set(
            text=f"Title: {max_df['title'].str}\mDescription: {max_df['summary'].str}\nDate: {date_str}\nOpen: {open_price:.2f}"
        )

    fig.autofmt_xdate()
    plt.show()


show_plot(max_open_date, True)
show_plot(min_open_date, False)
